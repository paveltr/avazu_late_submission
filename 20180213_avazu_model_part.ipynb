{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder # libFM part\n",
    "from sklearn.datasets import dump_svmlight_file # libFM part\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def df_shuffle(df):\n",
    "    df = shuffle(df)\n",
    "    df.reset_index(inplace = True)\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def libffm(ffm_p, tr_p, v_p, latent, cores, autostop = True, lreg = 0.00002, nrounds = 200, print_s = True, on_disc = False):\n",
    "    \n",
    "    if autostop:\n",
    "        fm_cmd = r\"%s -p %s -s %s -k %s -l %s -t %s -r 0.2 --auto-stop %s\" % (ffm_p, v_p, cores, latent, str(lreg), \n",
    "                                                                                 str(nrounds), tr_p)\n",
    "    else:\n",
    "        fm_cmd = r\"%s -p %s -s %s -k %s -l %s -t %s -r 0.2 %s\" % (ffm_p, v_p, cores, latent, str(lreg), \n",
    "                                                                                 str(nrounds), tr_p)\n",
    "        \n",
    "    if on_disc:\n",
    "        fm_cmd = r\"%s  -p %s -s 4 -k 10 -t 200  --no-rand --on-disk --auto-stop %s\" % (ffm_p, v_p, tr_p)\n",
    "        print(os.popen(fm_cmd).read())\n",
    "        \n",
    "    else:\n",
    "        if print_s:\n",
    "            print(fm_cmd)\n",
    "        log = os.popen(fm_cmd).read()\n",
    "        print(log)\n",
    "        try:\n",
    "            result = log.split('\\n')\n",
    "            loss = float(result[len(result) - 4].split('      ')[2])\n",
    "        except:\n",
    "            loss = -1000\n",
    "        print('Val logloss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def libffm_predict(ffm_p, model_p, test_p,  out_p):\n",
    "    fm_cmd = r\"%s %s %s %s\" % (ffm_p, test_p, model_p, out_p)\n",
    "    print(fm_cmd)\n",
    "    try:\n",
    "        os.system(fm_cmd)\n",
    "        print('Predicted: 1')\n",
    "    except Exception as e:\n",
    "        print('Predicted: 0')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_to_ffm(df,type,numerics,categories,features, bpath, model_type = ''):\n",
    "        currentcode = len(numerics)\n",
    "        catdict = {}\n",
    "        catcodes = {}\n",
    "        # Flagging categorical and numerical fields\n",
    "        for x in numerics:\n",
    "             catdict[x] = 0\n",
    "        for x in categories:\n",
    "             catdict[x] = 1\n",
    "\n",
    "        nrows = df.shape[0]\n",
    "        ncolumns = len(features)\n",
    "        counter = 0\n",
    "        with open(bpath + str(type) + \"_\" + model_type + \"_ffm.txt\", \"w\") as text_file:\n",
    "\n",
    "            # Looping over rows to convert each row to libffm format\n",
    "            for n, r in enumerate(range(nrows)):\n",
    "                datastring = \"\"\n",
    "                datarow = df.iloc[r].to_dict()\n",
    "                datastring += str(int(datarow['click']))\n",
    "                # For numerical fields, we are creating a dummy field here\n",
    "                for i, x in enumerate(catdict.keys()):\n",
    "                    if(catdict[x]==0):\n",
    "                        datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "                    else:\n",
    "                 # For a new field appearing in a training example\n",
    "                        if(x not in catcodes):\n",
    "                            catcodes[x] = {}\n",
    "                            currentcode +=1\n",
    "                            catcodes[x][datarow[x]] = currentcode #encoding the feature\n",
    "                 # For already encoded fields\n",
    "                        elif(datarow[x] not in catcodes[x]):\n",
    "                            currentcode +=1\n",
    "                            catcodes[x][datarow[x]] = currentcode #encoding the feature\n",
    "                        code = catcodes[x][datarow[x]]\n",
    "                        datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "\n",
    "                datastring += '\\n'\n",
    "                text_file.write(datastring)\n",
    "                if counter % 10**5 == 0:\n",
    "                    print('Completed: ', round(counter / nrows, 2))\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_hour(x):\n",
    "    return int(str(x)[6:])\n",
    "\n",
    "def get_date(x):\n",
    "    return int(str(x)[:6])\n",
    "\n",
    "dict_day = {'21' : 1, '22' : 2, '23' : 3, '24' : 4, '25' : 5, '26' : 6, '27' : 0, '28' : 1, '29' : 2, '30' : 3, '31' : 4}\n",
    "def get_day(x):\n",
    "    return dict_day[str(x)[4:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_path = 'D:/Downloads/avazu_feedzai/'\n",
    "\n",
    "\n",
    "libffm_path = r'D:\\Downloads\\avazu_feedzai\\libffm\\ffm-train.exe'\n",
    "libffm_ftlr_path = r'D:\\Downloads\\avazu_feedzai\\libffm-ftrl-master\\libffm-ftrl-master\\ffm-train.exe'\n",
    "libffm_path_predict = r'D:\\Downloads\\avazu_feedzai\\libffm\\ffm-predict.exe'\n",
    "libffm_ftlr_predict = r'D:\\Downloads\\avazu_feedzai\\libffm-ftrl-master\\libffm-ftrl-master\\ffm-predict.exe'\n",
    "\n",
    "train_libffm = r'D:\\Downloads\\avazu_feedzai\\train_ffm.txt'\n",
    "val_libffm = r'D:\\Downloads\\avazu_feedzai\\val_ffm.txt'\n",
    "test_libffm = r'D:\\Downloads\\avazu_feedzai\\val_ffm.txt'\n",
    "\n",
    "train_libffm_m = r'D:\\Downloads\\avazu_feedzai\\train_mob_ffm.txt'\n",
    "val_libffm_m = r'D:\\Downloads\\avazu_feedzai\\val_mob_ffm.txt'\n",
    "test_libffm_m = r'D:\\Downloads\\avazu_feedzai\\test_mob_ffm.txt'\n",
    "\n",
    "train_libffm_a = r'D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt'\n",
    "val_libffm_a = r'D:\\Downloads\\avazu_feedzai\\val_app_ffm.txt'\n",
    "test_libffm_a = r'D:\\Downloads\\avazu_feedzai\\test_app_ffm.txt'\n",
    "\n",
    "out_a = r'D:\\Downloads\\avazu_feedzai\\app_ffm.txt'\n",
    "out_m = r'D:\\Downloads\\avazu_feedzai\\mob_ffm.txt'\n",
    "\n",
    "model_a = r'D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt.model'\n",
    "model_m = r'D:\\Downloads\\avazu_feedzai\\train_mob_ffm.txt.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_features(base_path, model_type, nrows):\n",
    "\n",
    "    train = pd.read_csv(base_path + 'train.gz', nrows = nrows)\n",
    "    # train['web'] = 1 - (train['site_id'] == '85f751fd')*1\n",
    "    if model_type == 'app':\n",
    "        train = train[train['site_id'] == '85f751fd']\n",
    "    else:\n",
    "        train = train[train['site_id'] != '85f751fd']\n",
    "        \n",
    "    print(\"Sample set shape: \",  train.shape[0])\n",
    "\n",
    "    train_index = int(0.8*train.shape[0])\n",
    "\n",
    "    train = df_shuffle(train)\n",
    "\n",
    "    # process hour\n",
    "\n",
    "    train['day'] = train['hour'].map(get_day)\n",
    "    train['time'] = train['hour'].map(get_hour)\n",
    "    train['date'] = train['hour'].map(get_date)\n",
    "\n",
    "    # generate features\n",
    "\n",
    "    # define user as device_id + device_model + device_ip\n",
    "\n",
    "    train['user'] = train['device_id'] + train['device_model'] + train['device_ip']\n",
    "\n",
    "    # for each user we calculate his characteristics per hour, per day, total\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        dicty = train.groupby('temp')['user'].count()\n",
    "        train['user' + '_count_' + c] = train['temp'].map(dicty)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        for cc in ['site_id', 'site_domain', 'site_category', 'app_id', 'app_domain',  'app_category', 'C14',\n",
    "           'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']:\n",
    "            dicty = train.groupby('temp')[cc].nunique()\n",
    "            train['user' + '_nunique_' + c + '_' + cc] = train['temp'].map(dicty)\n",
    "            if abs(train[['user' + '_nunique_' + c + '_' + cc, 'click']].corr().values[0][1]) < 0.05:\n",
    "                train.drop('user' + '_nunique_' + c + '_' + cc, axis = 1, inplace = True)\n",
    "                print('drop user' + '_nunique_' + c + '_' + cc)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    train.head(5)\n",
    "\n",
    "    # define an interaction of ad as site_id + app_id\n",
    "    \n",
    "    train['place_id'] = train['site_id'] + train['app_id']\n",
    "    train['place_genre_id'] = train['site_id'] + train['app_id'] + train['site_category'] + train['app_category']\n",
    "    train['tech_position'] = train['banner_pos'].astype(str) + train['device_conn_type'].astype(str)\n",
    "    train['add_position'] = train['place_id'].astype(str) + train['banner_pos'].astype(str)\n",
    "    train['union_category'] = train['site_category'] + train['app_category']\n",
    "\n",
    "    train['ultra_C_type'] = train['C1'].astype(str) + train['C14'].astype(str) + train['C15'].astype(str) + train['C16'].astype(str) \\\n",
    "     + train['C17'].astype(str) + train['C18'].astype(str) + train['C19'].astype(str) + train['C20'].astype(str)+ train['C21'].astype(str)\n",
    "\n",
    "    # for features we calculate how oftern they are met per hour, per day and in total\n",
    "\n",
    "    train['user_date'] = train['user'].astype(str) + train['date'].astype(str)\n",
    "    train['place_date'] = train['place_id'].astype(str) + train['date'].astype(str)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    history_user = []\n",
    "    history_place = []\n",
    "\n",
    "    dict_user = {}\n",
    "    dict_place = {}\n",
    "\n",
    "    for row in train.itertuples():\n",
    "\n",
    "        user = row[list(train.columns).index('user_date') + 1]\n",
    "        place = row[list(train.columns).index('place_date') + 1]\n",
    "\n",
    "\n",
    "        try:\n",
    "            history_user.append(dict_user[user])\n",
    "        except KeyError:\n",
    "            history_user.append(0)\n",
    "        try:\n",
    "            history_place.append(dict_place[place])\n",
    "        except KeyError:\n",
    "            history_place.append(0)\n",
    "\n",
    "\n",
    "        try:\n",
    "            dict_user[user] += 1\n",
    "        except KeyError:\n",
    "            dict_user[user] = 0\n",
    "        try:\n",
    "            dict_place[place] += 1\n",
    "        except KeyError:\n",
    "            dict_place[place] = 0\n",
    "\n",
    "        if counter % 10**6 == 0:\n",
    "            print(counter / train.shape[0])\n",
    "        counter += 1\n",
    "\n",
    "    train['user_history'] = history_user\n",
    "    train.ix[train['user_history'] > 10*3, 'user_history'] = 1000\n",
    "    train['place_history'] = history_place\n",
    "    train.ix[train['place_history'] > 10*3, 'place_history'] = 1000\n",
    "    \n",
    "    train.drop(['user_date', 'place_date'], axis = 1, inplace = True)\n",
    "\n",
    "    # check how many unique values we have got\n",
    "\n",
    "    for c in train.columns:\n",
    "        print('Column %s contains %s unique values. It is %s' % (c, train[c].nunique(), round((train[c].nunique() / train.shape[0]) * 100, 2))  + ' %')\n",
    "\n",
    "    avoid = ['click', 'hour', 'id', 'date']\n",
    "    features = [t for t in train.columns if t not in avoid]\n",
    "\n",
    "    # delete columns with 1 unique values\n",
    "    drop_cols = []\n",
    "    for c in features:\n",
    "        if train[c].nunique() == 1:\n",
    "            features.remove(c)\n",
    "\n",
    "    # replace values with low frequency\n",
    "    for c in features:\n",
    "        dicty = train.groupby(c)['click'].count()\n",
    "        train['temp'] = train[c].map(dicty)\n",
    "        train.ix[train['temp'] < 10, c] = -999\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "    return features, train\n",
    "\n",
    "# Save features\n",
    "\n",
    "def save_ffm(train, bpath, name, features):\n",
    "    convert_to_ffm(train,name,[],features,features, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Features for app model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set shape:  153042\n",
      "hour\n",
      "date\n",
      "drop user_nunique_hour_app_id\n",
      "drop user_nunique_hour_app_domain\n",
      "drop user_nunique_hour_app_category\n",
      "drop user_nunique_hour_C14\n",
      "drop user_nunique_hour_C15\n",
      "drop user_nunique_hour_C16\n",
      "drop user_nunique_hour_C17\n",
      "drop user_nunique_hour_C18\n",
      "drop user_nunique_hour_C19\n",
      "drop user_nunique_hour_C21\n",
      "hour\n",
      "drop user_nunique_date_app_id\n",
      "drop user_nunique_date_app_domain\n",
      "drop user_nunique_date_app_category\n",
      "drop user_nunique_date_C14\n",
      "drop user_nunique_date_C15\n",
      "drop user_nunique_date_C16\n",
      "drop user_nunique_date_C17\n",
      "drop user_nunique_date_C18\n",
      "drop user_nunique_date_C19\n",
      "drop user_nunique_date_C21\n",
      "date\n",
      "0.0\n",
      "Column id contains 153042 unique values. It is 100.0 %\n",
      "Column click contains 2 unique values. It is 0.0 %\n",
      "Column hour contains 4 unique values. It is 0.0 %\n",
      "Column C1 contains 7 unique values. It is 0.0 %\n",
      "Column banner_pos contains 4 unique values. It is 0.0 %\n",
      "Column site_id contains 1 unique values. It is 0.0 %\n",
      "Column site_domain contains 1 unique values. It is 0.0 %\n",
      "Column site_category contains 1 unique values. It is 0.0 %\n",
      "Column app_id contains 1640 unique values. It is 1.07 %\n",
      "Column app_domain contains 122 unique values. It is 0.08 %\n",
      "Column app_category contains 20 unique values. It is 0.01 %\n",
      "Column device_id contains 33145 unique values. It is 21.66 %\n",
      "Column device_ip contains 63835 unique values. It is 41.71 %\n",
      "Column device_model contains 2823 unique values. It is 1.84 %\n",
      "Column device_type contains 4 unique values. It is 0.0 %\n",
      "Column device_conn_type contains 4 unique values. It is 0.0 %\n",
      "Column C14 contains 370 unique values. It is 0.24 %\n",
      "Column C15 contains 7 unique values. It is 0.0 %\n",
      "Column C16 contains 8 unique values. It is 0.01 %\n",
      "Column C17 contains 113 unique values. It is 0.07 %\n",
      "Column C18 contains 4 unique values. It is 0.0 %\n",
      "Column C19 contains 33 unique values. It is 0.02 %\n",
      "Column C20 contains 148 unique values. It is 0.1 %\n",
      "Column C21 contains 31 unique values. It is 0.02 %\n",
      "Column day contains 1 unique values. It is 0.0 %\n",
      "Column time contains 4 unique values. It is 0.0 %\n",
      "Column date contains 1 unique values. It is 0.0 %\n",
      "Column user contains 74349 unique values. It is 48.58 %\n",
      "Column user_count_hour contains 89 unique values. It is 0.06 %\n",
      "Column user_count_date contains 106 unique values. It is 0.07 %\n",
      "Column user_nunique_hour_site_id contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_site_domain contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_site_category contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C20 contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_site_id contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_site_domain contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_site_category contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C20 contains 1 unique values. It is 0.0 %\n",
      "Column place_id contains 1640 unique values. It is 1.07 %\n",
      "Column place_genre_id contains 1640 unique values. It is 1.07 %\n",
      "Column tech_position contains 10 unique values. It is 0.01 %\n",
      "Column add_position contains 1643 unique values. It is 1.07 %\n",
      "Column union_category contains 20 unique values. It is 0.01 %\n",
      "Column ultra_C_type contains 1742 unique values. It is 1.14 %\n",
      "Column user_history contains 32 unique values. It is 0.02 %\n",
      "Column place_history contains 32 unique values. It is 0.02 %\n",
      "Completed:  0.0\n",
      "Completed:  0.82\n",
      "Completed:  0.0\n"
     ]
    }
   ],
   "source": [
    "features, train = get_features(base_path, 'app', 5*10**5)\n",
    "train_index = int(0.8*train.shape[0])\n",
    "save_ffm(train.ix[:train_index,:], base_path, 'train', features)\n",
    "save_ffm(train.ix[train_index:,:], base_path, 'val', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\avazu_feedzai\\libffm\\ffm-train.exe -p D:\\Downloads\\avazu_feedzai\\val_ffm.txt -s 6 -k 6 -l 2e-05 -t 200 -r 0.2 --auto-stop D:\\Downloads\\avazu_feedzai\\train_ffm.txt\n",
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "iter   tr_logloss   va_logloss      tr_time\n",
      "   1      0.44175      0.43207          2.4\n",
      "   2      0.43137      0.42884          4.8\n",
      "   3      0.42874      0.42670          7.2\n",
      "\n",
      "Val logloss:  0.43207\n"
     ]
    }
   ],
   "source": [
    "libffm(libffm_path,train_libffm, val_libffm, 6, 6, lreg = 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Features for mob model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set shape:  790\n",
      "hour\n",
      "date\n",
      "drop user_nunique_hour_site_id\n",
      "drop user_nunique_hour_site_domain\n",
      "drop user_nunique_hour_site_category\n",
      "drop user_nunique_hour_C14\n",
      "hour\n",
      "drop user_nunique_date_site_id\n",
      "drop user_nunique_date_site_domain\n",
      "drop user_nunique_date_site_category\n",
      "drop user_nunique_date_C14\n",
      "date\n",
      "0.0\n",
      "Column id contains 790 unique values. It is 100.0 %\n",
      "Column click contains 2 unique values. It is 0.25 %\n",
      "Column hour contains 1 unique values. It is 0.13 %\n",
      "Column C1 contains 3 unique values. It is 0.38 %\n",
      "Column banner_pos contains 2 unique values. It is 0.25 %\n",
      "Column site_id contains 121 unique values. It is 15.32 %\n",
      "Column site_domain contains 109 unique values. It is 13.8 %\n",
      "Column site_category contains 10 unique values. It is 1.27 %\n",
      "Column app_id contains 1 unique values. It is 0.13 %\n",
      "Column app_domain contains 1 unique values. It is 0.13 %\n",
      "Column app_category contains 1 unique values. It is 0.13 %\n",
      "Column device_id contains 33 unique values. It is 4.18 %\n",
      "Column device_ip contains 708 unique values. It is 89.62 %\n",
      "Column device_model contains 268 unique values. It is 33.92 %\n",
      "Column device_type contains 2 unique values. It is 0.25 %\n",
      "Column device_conn_type contains 2 unique values. It is 0.25 %\n",
      "Column C14 contains 76 unique values. It is 9.62 %\n",
      "Column C15 contains 3 unique values. It is 0.38 %\n",
      "Column C16 contains 3 unique values. It is 0.38 %\n",
      "Column C17 contains 46 unique values. It is 5.82 %\n",
      "Column C18 contains 3 unique values. It is 0.38 %\n",
      "Column C19 contains 19 unique values. It is 2.41 %\n",
      "Column C20 contains 38 unique values. It is 4.81 %\n",
      "Column C21 contains 17 unique values. It is 2.15 %\n",
      "Column day contains 1 unique values. It is 0.13 %\n",
      "Column time contains 1 unique values. It is 0.13 %\n",
      "Column date contains 1 unique values. It is 0.13 %\n",
      "Column user contains 763 unique values. It is 96.58 %\n",
      "Column user_count_hour contains 4 unique values. It is 0.51 %\n",
      "Column user_count_date contains 4 unique values. It is 0.51 %\n",
      "Column user_nunique_hour_app_id contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_app_domain contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_app_category contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_C15 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_C16 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_C17 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_C18 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_C19 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_C20 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_hour_C21 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_app_id contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_app_domain contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_app_category contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_C15 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_C16 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_C17 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_C18 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_C19 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_C20 contains 1 unique values. It is 0.13 %\n",
      "Column user_nunique_date_C21 contains 1 unique values. It is 0.13 %\n",
      "Column place_id contains 121 unique values. It is 15.32 %\n",
      "Column place_genre_id contains 121 unique values. It is 15.32 %\n",
      "Column tech_position contains 4 unique values. It is 0.51 %\n",
      "Column add_position contains 122 unique values. It is 15.44 %\n",
      "Column union_category contains 10 unique values. It is 1.27 %\n",
      "Column ultra_C_type contains 161 unique values. It is 20.38 %\n",
      "Column user_history contains 3 unique values. It is 0.38 %\n",
      "Column place_history contains 32 unique values. It is 4.05 %\n",
      "Completed:  0.0\n",
      "Completed:  0.0\n"
     ]
    }
   ],
   "source": [
    "features, train = get_features(base_path, 'mob', 10**3)\n",
    "train_index = int(0.8*train.shape[0])\n",
    "save_ffm(train.ix[:train_index,:], base_path, 'train', features)\n",
    "save_ffm(train.ix[train_index:,:], base_path, 'val', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\avazu_feedzai\\libffm\\ffm-train.exe -p D:\\Downloads\\avazu_feedzai\\val_ffm.txt -s 6 -k 10 -l 2e-05 -t 200 -r 0.2 --auto-stop D:\\Downloads\\avazu_feedzai\\train_ffm.txt\n",
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "iter   tr_logloss   va_logloss      tr_time\n",
      "   1      0.44192      0.43186          3.1\n",
      "   2      0.43141      0.42890          6.2\n",
      "   3      0.42866      0.42672          9.2\n",
      "   4      0.42663      0.42461         12.2\n",
      "\n",
      "Val logloss:  0.4289\n"
     ]
    }
   ],
   "source": [
    "libffm(libffm_path,train_libffm, val_libffm, 10, 6, lreg = 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['features'] = features\n",
    "sub.to_csv(base_path + 'features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training part for the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# app model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ffm_txt_full(train, base_path, model_type, features_list, sample_size = 1.0):\n",
    "\n",
    "    if model_type == 'app':\n",
    "        train = train[train['site_id'] == '85f751fd']\n",
    "    else:\n",
    "        train = train[train['site_id'] != '85f751fd']\n",
    "        \n",
    "        \n",
    "    # process hour\n",
    "\n",
    "    train['day'] = train['hour'].map(get_day)\n",
    "    train['time'] = train['hour'].map(get_hour)\n",
    "    train['date'] = train['hour'].map(get_date)\n",
    "\n",
    "    # generate features\n",
    "\n",
    "    # define user as device_id + device_model + device_ip\n",
    "\n",
    "    train['user'] = train['device_id'] + train['device_model'] + train['device_ip']\n",
    "\n",
    "    # for each user we calculate his characteristics per hour, per day, total\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        dicty = train.groupby('temp')['user'].count()\n",
    "        train['user' + '_count_' + c] = train['temp'].map(dicty)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        for cc in ['site_id', 'site_domain', 'site_category', 'app_id', 'app_domain',  'app_category', 'C14',\n",
    "           'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']:\n",
    "            dicty = train.groupby('temp')[cc].nunique()\n",
    "            train['user' + '_nunique_' + c + '_' + cc] = train['temp'].map(dicty)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    # define an interaction of ad as site_id + app_id\n",
    "\n",
    "    train['place_id'] = train['site_id'] + train['app_id']\n",
    "    train['place_genre_id'] = train['site_id'] + train['app_id'] + train['site_category'] + train['app_category']\n",
    "    train['tech_position'] = train['banner_pos'].astype(str) + train['device_conn_type'].astype(str)\n",
    "    train['add_position'] = train['place_id'].astype(str) + train['banner_pos'].astype(str)\n",
    "    train['union_category'] = train['site_category'] + train['app_category']\n",
    "\n",
    "    train['ultra_C_type'] = train['C1'].astype(str) + train['C14'].astype(str) + train['C15'].astype(str) + train['C16'].astype(str) \\\n",
    "     + train['C17'].astype(str) + train['C18'].astype(str) + train['C19'].astype(str) + train['C20'].astype(str)+ train['C21'].astype(str)\n",
    "\n",
    "    \n",
    "\n",
    "    train['user_date'] = train['user'].astype(str) + train['date'].astype(str)\n",
    "    train['place_date'] = train['place_id'].astype(str) + train['date'].astype(str)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    history_user = []\n",
    "    history_place = []\n",
    "\n",
    "    dict_user = {}\n",
    "    dict_place = {}\n",
    "    \n",
    "    # for features user and place we calculate how oftern they are met per date in cummulative way\n",
    "\n",
    "    for row in train.itertuples():\n",
    "\n",
    "        user = row[list(train.columns).index('user_date') + 1]\n",
    "        place = row[list(train.columns).index('place_date') + 1]\n",
    "\n",
    "\n",
    "        try:\n",
    "            history_user.append(dict_user[user])\n",
    "        except KeyError:\n",
    "            history_user.append(0)\n",
    "        try:\n",
    "            history_place.append(dict_place[place])\n",
    "        except KeyError:\n",
    "            history_place.append(0)\n",
    "\n",
    "\n",
    "        try:\n",
    "            dict_user[user] += 1\n",
    "        except KeyError:\n",
    "            dict_user[user] = 0\n",
    "        try:\n",
    "            dict_place[place] += 1\n",
    "        except KeyError:\n",
    "            dict_place[place] = 0\n",
    "\n",
    "        if counter % 10**6 == 0:\n",
    "            print(counter / train.shape[0])\n",
    "        counter += 1\n",
    "\n",
    "    train['user_history'] = history_user\n",
    "    train.ix[train['user_history'] > 10*3, 'user_history'] = 1000\n",
    "    train['place_history'] = history_place\n",
    "    train.ix[train['place_history'] > 10*3, 'place_history'] = 1000\n",
    "    \n",
    "    train.drop(['user_date', 'place_date'], axis = 1, inplace = True)\n",
    "    \n",
    "    train = pd.concat([train[train['type'] == 1].sample(frac=sample_size, replace=False, random_state = 1),\n",
    "                       train[train['type'] == 0]])\n",
    "    \n",
    "    train.reset_index(inplace = True)\n",
    "    train.drop('index', inplace = True, axis = 1)\n",
    "        \n",
    "    train_shape = train[train['type'] == 1].shape[0]\n",
    "    train.drop('type', axis = 1, inplace = True)\n",
    "    \n",
    "    train_index = int(0.8*train_shape)\n",
    "    convert_to_ffm(train.ix[:train_index, :],'train',[],features_list,features_list, base_path, model_type = model_type)\n",
    "    convert_to_ffm(train.ix[train_index:train_shape - 1, :],'val',[],features_list,features_list, base_path, model_type = model_type)\n",
    "    convert_to_ffm(train.ix[train_shape:, :],'test',[],features_list,features_list, base_path, model_type = model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(base_path + 'train.gz')\n",
    "test = pd.read_csv(base_path + 'test.gz')\n",
    "test['click'] = 0\n",
    "\n",
    "train['type'] = 1\n",
    "test['type'] = 0\n",
    "\n",
    "cols = [t for t in train.columns]\n",
    "data = pd.concat([train[cols], test[cols]])\n",
    "\n",
    "\n",
    "features = list(pd.read_csv(base_path + 'features.csv')['features'].values)\n",
    "\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_ffm_txt_full(data, base_path, 'app', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mob model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(base_path + 'train.gz')\n",
    "test = pd.read_csv(base_path + 'test.gz')\n",
    "test['click'] = 0\n",
    "\n",
    "train['type'] = 1\n",
    "test['type'] = 0\n",
    "\n",
    "cols = [t for t in train.columns]\n",
    "data = pd.concat([train[cols], test[cols]])\n",
    "\n",
    "\n",
    "features = list(pd.read_csv(base_path + 'features.csv')['features'].values)\n",
    "\n",
    "del train\n",
    "del test\n",
    "\n",
    "get_ffm_txt_full(data, base_path, 'mob', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training and prediction for app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Downloads\\avazu_feedzai\\ffm_txt\\train_app_ffm.txt', nrows = 10**6, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\Downloads\\avazu_feedzai\\ffm_txt\\train_app_ffmm.txt', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "libffm(libffm_path, train_libffm_a, val_libffm_a, 10, 6, autostop = True, lreg = 0.00002, print_s = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\avazu_feedzai\\libffm\\ffm-predict.exe D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt.model D:\\Downloads\\avazu_feedzai\\app_ffm.txt\n",
      "Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "libffm_predict(libffm_path_predict, model_a, train_libffm_a,  out_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training and prediction for mob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First check if the text file has already converted to binary format (0.0 seconds)\n",
      "Binary file NOT found. Convert text file to binary file (273.6 seconds)\n",
      "First check if the text file has already converted to binary format (0.0 seconds)\n",
      "Binary file NOT found. Convert text file to binary file (69.3 seconds)\n",
      "iter   tr_logloss   va_logloss      tr_time\n",
      "\n",
      "Val logloss:  -1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libffm(libffm_path,train_libffm_m, val_libffm_m, 10, 6, lreg = 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "libffm_predict(libffm_path_predict, model_m, test_libffm_m,  out_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Combine libFFM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['site_id'] = test['site_id']\n",
    "sub['click'] = 0\n",
    "\n",
    "mob_pred = pd.read_csv(base_path + 'out_mob.txt', header = None)\n",
    "app_pred = pd.read_csv(base_path + 'out_app.txt', header = None)\n",
    "\n",
    "sub.ix[sub['site_id'] != '85f751fd', 'click'] = mob_pred[0].values\n",
    "sub.ix[sub['site_id'] == '85f751fd', 'click'] = app_pred[0].values\n",
    "\n",
    "sub[['id', 'click']].to_csv(base_path + 'submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
