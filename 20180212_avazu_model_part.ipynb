{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder # libFM part\n",
    "from sklearn.datasets import dump_svmlight_file # libFM part\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def df_shuffle(df):\n",
    "    df = shuffle(df)\n",
    "    df.reset_index(inplace = True)\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def libffm(ffm_p, tr_p, v_p, latent, cores, autostop = True, lreg = 0.00002, nrounds = 200, print_s = False, on_disc = False):\n",
    "    \n",
    "    if autostop:\n",
    "        fm_cmd = r\"%s -p %s -s %s -k %s -l %s -t %s -r 0.2 --auto-stop %s\" % (ffm_p, v_p, cores, latent, str(lreg), \n",
    "                                                                                 str(nrounds), tr_p)\n",
    "    else:\n",
    "        fm_cmd = r\"%s -p %s -s %s -k %s -l %s -t %s -r 0.2 %s\" % (ffm_p, v_p, cores, latent, str(lreg), \n",
    "                                                                                 str(nrounds), tr_p)\n",
    "        \n",
    "    if on_disc:\n",
    "        fm_cmd = r\"%s  -p %s -s 4 -k 10 -t 200  --no-rand --on-disk --auto-stop %s\" % (ffm_p, v_p, tr_p)\n",
    "        print(os.popen(fm_cmd).read())\n",
    "        \n",
    "    else:\n",
    "        if print_s:\n",
    "            print(fm_cmd)\n",
    "        log = os.popen(fm_cmd).read()\n",
    "        print(log)\n",
    "        try:\n",
    "            result = log.split('\\n')\n",
    "            loss = float(result[len(result) - 4].split('      ')[2])\n",
    "        except:\n",
    "            loss = -1000\n",
    "        print('Val logloss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def libffm_predict(ffm_p, model_p, test_p,  out_p):\n",
    "    fm_cmd = r\"%s %s %s %s\" % (ffm_p, test_p, model_p, out_p)\n",
    "    print(fm_cmd)\n",
    "    try:\n",
    "        os.system(fm_cmd)\n",
    "        print('Predicted: 1')\n",
    "    except Exception as e:\n",
    "        print('Predicted: 0')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_to_ffm(df,type,numerics,categories,features, bpath, model_type = ''):\n",
    "        currentcode = len(numerics)\n",
    "        catdict = {}\n",
    "        catcodes = {}\n",
    "        # Flagging categorical and numerical fields\n",
    "        for x in numerics:\n",
    "             catdict[x] = 0\n",
    "        for x in categories:\n",
    "             catdict[x] = 1\n",
    "\n",
    "        nrows = df.shape[0]\n",
    "        ncolumns = len(features)\n",
    "        counter = 0\n",
    "        with open(bpath + str(type) + \"_\" + model_type + \"_ffm.txt\", \"w\") as text_file:\n",
    "\n",
    "            # Looping over rows to convert each row to libffm format\n",
    "            for n, r in enumerate(range(nrows)):\n",
    "                datastring = \"\"\n",
    "                datarow = df.iloc[r].to_dict()\n",
    "                datastring += str(int(datarow['click']))\n",
    "                # For numerical fields, we are creating a dummy field here\n",
    "                for i, x in enumerate(catdict.keys()):\n",
    "                    if(catdict[x]==0):\n",
    "                        datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "                    else:\n",
    "                 # For a new field appearing in a training example\n",
    "                        if(x not in catcodes):\n",
    "                            catcodes[x] = {}\n",
    "                            currentcode +=1\n",
    "                            catcodes[x][datarow[x]] = currentcode #encoding the feature\n",
    "                 # For already encoded fields\n",
    "                        elif(datarow[x] not in catcodes[x]):\n",
    "                            currentcode +=1\n",
    "                            catcodes[x][datarow[x]] = currentcode #encoding the feature\n",
    "                        code = catcodes[x][datarow[x]]\n",
    "                        datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "\n",
    "                datastring += '\\n'\n",
    "                text_file.write(datastring)\n",
    "                if counter % 10**5 == 0:\n",
    "                    print('Completed: ', round(counter / nrows, 2))\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ftlr(path):  \n",
    "    os.system(\"python %s\" %path)\n",
    "\n",
    "def get_hour(x):\n",
    "    return int(str(x)[6:])\n",
    "\n",
    "def get_date(x):\n",
    "    return int(str(x)[:6])\n",
    "\n",
    "dict_day = {'21' : 1, '22' : 2, '23' : 3, '24' : 4, '25' : 5, '26' : 6, '27' : 0, '28' : 1, '29' : 2, '30' : 3, '31' : 4}\n",
    "def get_day(x):\n",
    "    return dict_day[str(x)[4:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_path = 'D:/Downloads/avazu_feedzai/'\n",
    "ftlr_path = r'D:\\Downloads\\avazu_feedzai\\ftlr\\ftlr.py'\n",
    "\n",
    "\n",
    "libffm_path = r'D:\\Downloads\\avazu_feedzai\\libffm\\ffm-train.exe'\n",
    "libffm_ftlr_path = r'D:\\Downloads\\avazu_feedzai\\libffm-ftrl-master\\libffm-ftrl-master\\ffm-train.exe'\n",
    "libffm_path_predict = r'D:\\Downloads\\avazu_feedzai\\libffm\\ffm-predict.exe'\n",
    "libffm_ftlr_predict = r'D:\\Downloads\\avazu_feedzai\\libffm-ftrl-master\\libffm-ftrl-master\\ffm-predict.exe'\n",
    "\n",
    "train_libffm = r'D:\\Downloads\\avazu_feedzai\\train_ffm.txt'\n",
    "val_libffm = r'D:\\Downloads\\avazu_feedzai\\val_ffm.txt'\n",
    "test_libffm = r'D:\\Downloads\\avazu_feedzai\\val_ffm.txt'\n",
    "\n",
    "train_libffm_m = r'D:\\Downloads\\avazu_feedzai\\train_mob_ffm.txt'\n",
    "val_libffm_m = r'D:\\Downloads\\avazu_feedzai\\val_mob_ffm.txt'\n",
    "test_libffm_m = r'D:\\Downloads\\avazu_feedzai\\test_mob_ffm.txt'\n",
    "\n",
    "train_libffm_a = r'D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt'\n",
    "val_libffm_a = r'D:\\Downloads\\avazu_feedzai\\val_app_ffm.txt'\n",
    "test_libffm_a = r'D:\\Downloads\\avazu_feedzai\\test_app_ffm.txt'\n",
    "\n",
    "out_a = r'D:\\Downloads\\avazu_feedzai\\app_ffm.txt'\n",
    "out_m = r'D:\\Downloads\\avazu_feedzai\\mob_ffm.txt'\n",
    "\n",
    "model_a = r'D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt.model'\n",
    "model_m = r'D:\\Downloads\\avazu_feedzai\\train_mob_ffm.txt.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_features(base_path, model_type, nrows):\n",
    "\n",
    "    train = pd.read_csv(base_path + 'train.gz', nrows = nrows)\n",
    "    # train['web'] = 1 - (train['site_id'] == '85f751fd')*1\n",
    "    if model_type == 'app':\n",
    "        train = train[train['site_id'] == '85f751fd']\n",
    "    else:\n",
    "        train = train[train['site_id'] != '85f751fd']\n",
    "        \n",
    "    print(\"Sample set shape: \",  train.shape[0])\n",
    "\n",
    "    train_index = int(0.8*train.shape[0])\n",
    "\n",
    "    train = df_shuffle(train)\n",
    "\n",
    "    # process hour\n",
    "\n",
    "    train['day'] = train['hour'].map(get_day)\n",
    "    train['time'] = train['hour'].map(get_hour)\n",
    "    train['date'] = train['hour'].map(get_date)\n",
    "\n",
    "    # generate features\n",
    "\n",
    "    # define user as device_id + device_model + device_ip\n",
    "\n",
    "    train['user'] = train['device_id'] + train['device_model'] + train['device_ip']\n",
    "\n",
    "    # for each user we calculate his characteristics per hour, per day, total\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        dicty = train.groupby('temp')['user'].count()\n",
    "        train['user' + '_count_' + c] = train['temp'].map(dicty)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        for cc in ['site_id', 'site_domain', 'site_category', 'app_id', 'app_domain',  'app_category', 'C14',\n",
    "           'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']:\n",
    "            dicty = train.groupby('temp')[cc].nunique()\n",
    "            train['user' + '_nunique_' + c + '_' + cc] = train['temp'].map(dicty)\n",
    "            if abs(train[['user' + '_nunique_' + c + '_' + cc, 'click']].corr().values[0][1]) < 0.05:\n",
    "                train.drop('user' + '_nunique_' + c + '_' + cc, axis = 1, inplace = True)\n",
    "                print('drop user' + '_nunique_' + c + '_' + cc)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    train.head(5)\n",
    "\n",
    "    # define an interaction of ad as site_id + app_id\n",
    "    \n",
    "    train['place_id'] = train['site_id'] + train['app_id']\n",
    "    train['place_genre_id'] = train['site_id'] + train['app_id'] + train['site_category'] + train['app_category']\n",
    "    train['tech_position'] = train['banner_pos'].astype(str) + train['device_conn_type'].astype(str)\n",
    "    train['add_position'] = train['place_id'].astype(str) + train['banner_pos'].astype(str)\n",
    "    train['union_category'] = train['site_category'] + train['app_category']\n",
    "\n",
    "    train['ultra_C_type'] = train['C1'].astype(str) + train['C14'].astype(str) + train['C15'].astype(str) + train['C16'].astype(str) \\\n",
    "     + train['C17'].astype(str) + train['C18'].astype(str) + train['C19'].astype(str) + train['C20'].astype(str)+ train['C21'].astype(str)\n",
    "\n",
    "    # for features we calculate how oftern they are met per hour, per day and in total\n",
    "\n",
    "    train['user_date'] = train['user'].astype(str) + train['date'].astype(str)\n",
    "    train['place_date'] = train['place_id'].astype(str) + train['date'].astype(str)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    history_user = []\n",
    "    history_place = []\n",
    "\n",
    "    dict_user = {}\n",
    "    dict_place = {}\n",
    "\n",
    "    for row in train.itertuples():\n",
    "\n",
    "        user = row[list(train.columns).index('user_date') + 1]\n",
    "        place = row[list(train.columns).index('place_date') + 1]\n",
    "\n",
    "\n",
    "        try:\n",
    "            history_user.append(dict_user[user])\n",
    "        except KeyError:\n",
    "            history_user.append(0)\n",
    "        try:\n",
    "            history_place.append(dict_place[place])\n",
    "        except KeyError:\n",
    "            history_place.append(0)\n",
    "\n",
    "\n",
    "        try:\n",
    "            dict_user[user] += 1\n",
    "        except KeyError:\n",
    "            dict_user[user] = 0\n",
    "        try:\n",
    "            dict_place[place] += 1\n",
    "        except KeyError:\n",
    "            dict_place[place] = 0\n",
    "\n",
    "        if counter % 10**6 == 0:\n",
    "            print(counter / train.shape[0])\n",
    "        counter += 1\n",
    "\n",
    "    train['user_history'] = history_user\n",
    "    train.ix[train['user_history'] > 10*3, 'user_history'] = 1000\n",
    "    train['place_history'] = history_place\n",
    "    train.ix[train['place_history'] > 10*3, 'place_history'] = 1000\n",
    "    \n",
    "    train.drop(['user_date', 'place_date'], axis = 1, inplace = True)\n",
    "\n",
    "    # check how many unique values we have got\n",
    "\n",
    "    for c in train.columns:\n",
    "        print('Column %s contains %s unique values. It is %s' % (c, train[c].nunique(), round((train[c].nunique() / train.shape[0]) * 100, 2))  + ' %')\n",
    "\n",
    "    avoid = ['click', 'hour', 'id', 'date']\n",
    "    features = [t for t in train.columns if t not in avoid]\n",
    "\n",
    "    # delete columns with 1 unique values\n",
    "    drop_cols = []\n",
    "    for c in features:\n",
    "        if train[c].nunique() == 1:\n",
    "            features.remove(c)\n",
    "\n",
    "    # replace values with low frequency\n",
    "    for c in features:\n",
    "        dicty = train.groupby(c)['click'].count()\n",
    "        train['temp'] = train[c].map(dicty)\n",
    "        train.ix[train['temp'] < 10, c] = -999\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "    return features, train\n",
    "\n",
    "# Save features\n",
    "\n",
    "def save_ffm(train, bpath, name, features):\n",
    "    convert_to_ffm(train,name,[],features,features, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Features for app model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set shape:  153042\n",
      "hour\n",
      "date\n",
      "drop user_nunique_hour_app_id\n",
      "drop user_nunique_hour_app_domain\n",
      "drop user_nunique_hour_app_category\n",
      "drop user_nunique_hour_C14\n",
      "drop user_nunique_hour_C15\n",
      "drop user_nunique_hour_C16\n",
      "drop user_nunique_hour_C17\n",
      "drop user_nunique_hour_C18\n",
      "drop user_nunique_hour_C19\n",
      "drop user_nunique_hour_C21\n",
      "hour\n",
      "drop user_nunique_date_app_id\n",
      "drop user_nunique_date_app_domain\n",
      "drop user_nunique_date_app_category\n",
      "drop user_nunique_date_C14\n",
      "drop user_nunique_date_C15\n",
      "drop user_nunique_date_C16\n",
      "drop user_nunique_date_C17\n",
      "drop user_nunique_date_C18\n",
      "drop user_nunique_date_C19\n",
      "drop user_nunique_date_C21\n",
      "date\n",
      "0.0\n",
      "Column id contains 153042 unique values. It is 100.0 %\n",
      "Column click contains 2 unique values. It is 0.0 %\n",
      "Column hour contains 4 unique values. It is 0.0 %\n",
      "Column C1 contains 7 unique values. It is 0.0 %\n",
      "Column banner_pos contains 4 unique values. It is 0.0 %\n",
      "Column site_id contains 1 unique values. It is 0.0 %\n",
      "Column site_domain contains 1 unique values. It is 0.0 %\n",
      "Column site_category contains 1 unique values. It is 0.0 %\n",
      "Column app_id contains 1640 unique values. It is 1.07 %\n",
      "Column app_domain contains 122 unique values. It is 0.08 %\n",
      "Column app_category contains 20 unique values. It is 0.01 %\n",
      "Column device_id contains 33145 unique values. It is 21.66 %\n",
      "Column device_ip contains 63835 unique values. It is 41.71 %\n",
      "Column device_model contains 2823 unique values. It is 1.84 %\n",
      "Column device_type contains 4 unique values. It is 0.0 %\n",
      "Column device_conn_type contains 4 unique values. It is 0.0 %\n",
      "Column C14 contains 370 unique values. It is 0.24 %\n",
      "Column C15 contains 7 unique values. It is 0.0 %\n",
      "Column C16 contains 8 unique values. It is 0.01 %\n",
      "Column C17 contains 113 unique values. It is 0.07 %\n",
      "Column C18 contains 4 unique values. It is 0.0 %\n",
      "Column C19 contains 33 unique values. It is 0.02 %\n",
      "Column C20 contains 148 unique values. It is 0.1 %\n",
      "Column C21 contains 31 unique values. It is 0.02 %\n",
      "Column day contains 1 unique values. It is 0.0 %\n",
      "Column time contains 4 unique values. It is 0.0 %\n",
      "Column date contains 1 unique values. It is 0.0 %\n",
      "Column user contains 74349 unique values. It is 48.58 %\n",
      "Column user_count_hour contains 89 unique values. It is 0.06 %\n",
      "Column user_count_date contains 106 unique values. It is 0.07 %\n",
      "Column user_nunique_hour_site_id contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_site_domain contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_site_category contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C20 contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_site_id contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_site_domain contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_site_category contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C20 contains 1 unique values. It is 0.0 %\n",
      "Column place_id contains 1640 unique values. It is 1.07 %\n",
      "Column place_genre_id contains 1640 unique values. It is 1.07 %\n",
      "Column tech_position contains 10 unique values. It is 0.01 %\n",
      "Column add_position contains 1643 unique values. It is 1.07 %\n",
      "Column union_category contains 20 unique values. It is 0.01 %\n",
      "Column ultra_C_type contains 1742 unique values. It is 1.14 %\n",
      "Column user_history contains 32 unique values. It is 0.02 %\n",
      "Column place_history contains 32 unique values. It is 0.02 %\n",
      "Completed:  0.0\n",
      "Completed:  0.82\n",
      "Completed:  0.0\n"
     ]
    }
   ],
   "source": [
    "features, train = get_features(base_path, 'app', 5*10**5)\n",
    "train_index = int(0.8*train.shape[0])\n",
    "save_ffm(train.ix[:train_index,:], base_path, 'train', features)\n",
    "save_ffm(train.ix[train_index:,:], base_path, 'val', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "iter   tr_logloss   va_logloss      tr_time\n",
      "   1      0.44151      0.43087          3.0\n",
      "   2      0.43039      0.42750          6.0\n",
      "   3      0.42707      0.42507          9.0\n",
      "   4      0.42408      0.42069         12.0\n",
      "   5      0.42099      0.41699         15.0\n",
      "   6      0.41731      0.41415         18.1\n",
      "   7      0.41358      0.40865         21.1\n",
      "   8      0.41024      0.40465         24.1\n",
      "   9      0.40702      0.40129         27.1\n",
      "  10      0.40385      0.39888         30.1\n",
      "  11      0.40135      0.39533         33.1\n",
      "  12      0.39872      0.39322         36.1\n",
      "  13      0.39634      0.38992         39.1\n",
      "  14      0.39400      0.38763         42.1\n",
      "  15      0.39148      0.38493         45.1\n",
      "  16      0.38887      0.38221         48.1\n",
      "  17      0.38666      0.37971         51.1\n",
      "  18      0.38413      0.37729         54.1\n",
      "  19      0.38183      0.37524         57.2\n",
      "  20      0.37931      0.37255         60.5\n",
      "  21      0.37704      0.36982         63.6\n",
      "  22      0.37478      0.36725         66.8\n",
      "  23      0.37220      0.36472         70.1\n",
      "  24      0.36993      0.36281         73.2\n",
      "  25      0.36778      0.36012         76.3\n",
      "  26      0.36527      0.35742         79.3\n",
      "  27      0.36311      0.35666         82.3\n",
      "  28      0.36103      0.35329         85.3\n",
      "  29      0.35861      0.35113         88.4\n",
      "  30      0.35665      0.34900         91.4\n",
      "  31      0.35459      0.34764         94.4\n",
      "  32      0.35255      0.34469         97.4\n",
      "  33      0.35027      0.34244        100.4\n",
      "  34      0.34814      0.34060        103.4\n",
      "  35      0.34620      0.33823        106.4\n",
      "  36      0.34417      0.33623        109.5\n",
      "  37      0.34243      0.33439        112.5\n",
      "  38      0.34051      0.33275        115.5\n",
      "  39      0.33844      0.33065        118.5\n",
      "  40      0.33667      0.32881        121.5\n",
      "  41      0.33458      0.32682        124.5\n",
      "  42      0.33277      0.32510        127.5\n",
      "  43      0.33094      0.32338        130.5\n",
      "  44      0.32934      0.32141        133.5\n",
      "  45      0.32747      0.31982        136.5\n",
      "  46      0.32566      0.31804        139.6\n",
      "  47      0.32394      0.31662        142.6\n",
      "  48      0.32217      0.31460        145.6\n",
      "  49      0.32051      0.31333        148.6\n",
      "  50      0.31883      0.31143        151.6\n",
      "  51      0.31719      0.31020        154.6\n",
      "  52      0.31550      0.30789        157.6\n",
      "  53      0.31391      0.30657        160.6\n",
      "  54      0.31248      0.30489        163.6\n",
      "  55      0.31064      0.30347        166.6\n",
      "  56      0.30911      0.30209        169.7\n",
      "  57      0.30754      0.30168        172.7\n",
      "  58      0.30599      0.29909        175.7\n",
      "  59      0.30469      0.29736        178.7\n",
      "  60      0.30296      0.29668        181.7\n",
      "  61      0.30153      0.29475        184.7\n",
      "  62      0.29992      0.29318        187.7\n",
      "  63      0.29859      0.29160        190.7\n",
      "  64      0.29719      0.29053        193.7\n",
      "  65      0.29586      0.28898        196.8\n",
      "  66      0.29446      0.28761        199.8\n",
      "  67      0.29283      0.28611        202.8\n",
      "  68      0.29153      0.28496        205.8\n",
      "  69      0.29027      0.28356        208.8\n",
      "  70      0.28899      0.28244        211.8\n",
      "  71      0.28766      0.28101        214.8\n",
      "  72      0.28636      0.27981        217.8\n",
      "  73      0.28486      0.27855        220.8\n",
      "  74      0.28370      0.27737        223.8\n",
      "  75      0.28247      0.27617        226.8\n",
      "  76      0.28129      0.27514        229.8\n",
      "  77      0.28011      0.27384        232.8\n",
      "  78      0.27891      0.27320        235.9\n",
      "  79      0.27774      0.27224        238.9\n",
      "  80      0.27643      0.27045        241.9\n",
      "  81      0.27521      0.26956        244.9\n",
      "  82      0.27430      0.26851        247.9\n",
      "  83      0.27326      0.26728        250.9\n",
      "  84      0.27205      0.26662        253.9\n",
      "  85      0.27092      0.26522        256.9\n",
      "  86      0.27008      0.26419        259.9\n",
      "  87      0.26908      0.26339        262.9\n",
      "  88      0.26812      0.26245        265.9\n",
      "  89      0.26715      0.26166        268.9\n",
      "  90      0.26605      0.26052        271.9\n",
      "  91      0.26498      0.25987        274.9\n",
      "  92      0.26428      0.25900        277.9\n",
      "  93      0.26342      0.25800        280.9\n",
      "  94      0.26254      0.25739        284.0\n",
      "  95      0.26167      0.25639        287.0\n",
      "  96      0.26068      0.25538        290.0\n",
      "  97      0.25990      0.25478        293.0\n",
      "  98      0.25896      0.25377        296.0\n",
      "  99      0.25828      0.25349        299.0\n",
      " 100      0.25746      0.25233        302.0\n",
      " 101      0.25665      0.25204        305.0\n",
      " 102      0.25599      0.25111        308.1\n",
      " 103      0.25514      0.25070        311.1\n",
      " 104      0.25450      0.24968        314.1\n",
      " 105      0.25381      0.24893        317.1\n",
      " 106      0.25295      0.24816        320.1\n",
      " 107      0.25235      0.24746        323.1\n",
      " 108      0.25159      0.24686        326.1\n",
      " 109      0.25097      0.24621        329.1\n",
      " 110      0.25025      0.24571        332.1\n",
      " 111      0.24974      0.24513        335.2\n",
      " 112      0.24916      0.24456        338.2\n",
      " 113      0.24841      0.24401        341.2\n",
      " 114      0.24785      0.24333        344.2\n",
      " 115      0.24714      0.24267        347.2\n",
      " 116      0.24666      0.24225        350.2\n",
      " 117      0.24610      0.24160        353.2\n",
      " 118      0.24545      0.24085        356.2\n",
      " 119      0.24495      0.24076        359.2\n",
      " 120      0.24427      0.23989        362.2\n",
      " 121      0.24384      0.23962        365.2\n",
      " 122      0.24332      0.23898        368.3\n",
      " 123      0.24266      0.23838        371.3\n",
      " 124      0.24221      0.23794        374.3\n",
      " 125      0.24161      0.23726        377.3\n",
      " 126      0.24116      0.23680        380.3\n",
      " 127      0.24076      0.23701\n",
      "Auto-stop. Use model at 126th iteration.\n",
      "\n",
      "Val logloss:  0.2368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2368"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libffm(libffm_path,train_libffm, val_libffm, 10, 6, lreg = 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Features for mob model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set shape:  346958\n",
      "hour\n",
      "date\n",
      "drop user_nunique_hour_site_id\n",
      "drop user_nunique_hour_site_domain\n",
      "drop user_nunique_hour_C14\n",
      "drop user_nunique_hour_C18\n",
      "hour\n",
      "drop user_nunique_date_site_id\n",
      "drop user_nunique_date_site_domain\n",
      "drop user_nunique_date_C14\n",
      "drop user_nunique_date_C18\n",
      "date\n",
      "0.0\n",
      "Column id contains 346958 unique values. It is 100.0 %\n",
      "Column click contains 2 unique values. It is 0.0 %\n",
      "Column hour contains 4 unique values. It is 0.0 %\n",
      "Column C1 contains 5 unique values. It is 0.0 %\n",
      "Column banner_pos contains 4 unique values. It is 0.0 %\n",
      "Column site_id contains 1703 unique values. It is 0.49 %\n",
      "Column site_domain contains 1586 unique values. It is 0.46 %\n",
      "Column site_category contains 21 unique values. It is 0.01 %\n",
      "Column app_id contains 1 unique values. It is 0.0 %\n",
      "Column app_domain contains 1 unique values. It is 0.0 %\n",
      "Column app_category contains 1 unique values. It is 0.0 %\n",
      "Column device_id contains 8269 unique values. It is 2.38 %\n",
      "Column device_ip contains 110964 unique values. It is 31.98 %\n",
      "Column device_model contains 3110 unique values. It is 0.9 %\n",
      "Column device_type contains 3 unique values. It is 0.0 %\n",
      "Column device_conn_type contains 2 unique values. It is 0.0 %\n",
      "Column C14 contains 424 unique values. It is 0.12 %\n",
      "Column C15 contains 5 unique values. It is 0.0 %\n",
      "Column C16 contains 5 unique values. It is 0.0 %\n",
      "Column C17 contains 122 unique values. It is 0.04 %\n",
      "Column C18 contains 4 unique values. It is 0.0 %\n",
      "Column C19 contains 30 unique values. It is 0.01 %\n",
      "Column C20 contains 148 unique values. It is 0.04 %\n",
      "Column C21 contains 29 unique values. It is 0.01 %\n",
      "Column day contains 1 unique values. It is 0.0 %\n",
      "Column time contains 4 unique values. It is 0.0 %\n",
      "Column date contains 1 unique values. It is 0.0 %\n",
      "Column user contains 154365 unique values. It is 44.49 %\n",
      "Column user_count_hour contains 128 unique values. It is 0.04 %\n",
      "Column user_count_date contains 143 unique values. It is 0.04 %\n",
      "Column user_nunique_hour_site_category contains 4 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_app_id contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_app_domain contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_app_category contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C15 contains 2 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C16 contains 2 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C17 contains 6 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C19 contains 4 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C20 contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_hour_C21 contains 5 unique values. It is 0.0 %\n",
      "Column user_nunique_date_site_category contains 5 unique values. It is 0.0 %\n",
      "Column user_nunique_date_app_id contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_app_domain contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_app_category contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C15 contains 3 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C16 contains 3 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C17 contains 7 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C19 contains 5 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C20 contains 1 unique values. It is 0.0 %\n",
      "Column user_nunique_date_C21 contains 5 unique values. It is 0.0 %\n",
      "Column place_id contains 1703 unique values. It is 0.49 %\n",
      "Column place_genre_id contains 1703 unique values. It is 0.49 %\n",
      "Column tech_position contains 7 unique values. It is 0.0 %\n",
      "Column add_position contains 1726 unique values. It is 0.5 %\n",
      "Column union_category contains 21 unique values. It is 0.01 %\n",
      "Column ultra_C_type contains 2255 unique values. It is 0.65 %\n",
      "Column user_history contains 32 unique values. It is 0.01 %\n",
      "Column place_history contains 32 unique values. It is 0.01 %\n",
      "Completed:  0.0\n",
      "Completed:  0.36\n",
      "Completed:  0.72\n",
      "Completed:  0.0\n"
     ]
    }
   ],
   "source": [
    "features, train = get_features(base_path, 'mob', 5*10**5)\n",
    "train_index = int(0.8*train.shape[0])\n",
    "save_ffm(train.ix[:train_index,:], base_path, 'train', features)\n",
    "save_ffm(train.ix[train_index:,:], base_path, 'val', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "First check if the text file has already converted to binary format (0.2 seconds)\n",
      "Binary file found. Skip converting text to binary\n",
      "iter   tr_logloss   va_logloss      tr_time\n",
      "   1      0.44144      0.43062          3.1\n",
      "   2      0.43043      0.42717          6.1\n",
      "   3      0.42706      0.42396          9.1\n",
      "   4      0.42407      0.42148         12.1\n",
      "   5      0.42097      0.41658         15.1\n",
      "   6      0.41730      0.41304         18.1\n",
      "   7      0.41362      0.40901         21.1\n",
      "   8      0.41027      0.40492         24.1\n",
      "   9      0.40702      0.40138         27.1\n",
      "  10      0.40387      0.39911         30.1\n",
      "  11      0.40133      0.39541         33.1\n",
      "  12      0.39871      0.39404         36.1\n",
      "  13      0.39636      0.38995         39.1\n",
      "  14      0.39402      0.38731         42.1\n",
      "  15      0.39152      0.38521         45.2\n",
      "  16      0.38890      0.38227         48.2\n",
      "  17      0.38668      0.37961         51.2\n",
      "  18      0.38414      0.37754         54.2\n",
      "  19      0.38187      0.37560         57.2\n",
      "  20      0.37931      0.37242         60.2\n",
      "  21      0.37704      0.36980         63.3\n",
      "  22      0.37477      0.36724         66.4\n",
      "  23      0.37222      0.36469         69.5\n",
      "  24      0.36994      0.36266         72.6\n",
      "  25      0.36779      0.36018         75.8\n",
      "  26      0.36524      0.35745         78.8\n",
      "  27      0.36305      0.35577         81.8\n",
      "  28      0.36102      0.35394         84.8\n",
      "  29      0.35858      0.35128         87.9\n",
      "  30      0.35663      0.34891         90.9\n",
      "  31      0.35454      0.34715         93.9\n",
      "  32      0.35250      0.34460         97.0\n",
      "  33      0.35023      0.34240         99.9\n",
      "  34      0.34808      0.34043        103.0\n",
      "  35      0.34614      0.33816        105.9\n",
      "  36      0.34410      0.33628        109.0\n",
      "  37      0.34236      0.33464        112.1\n",
      "  38      0.34047      0.33256        115.1\n",
      "  39      0.33836      0.33166        118.1\n",
      "  40      0.33663      0.32870        121.1\n",
      "  41      0.33452      0.32685        124.1\n",
      "  42      0.33270      0.32518        127.2\n",
      "  43      0.33091      0.32319        130.1\n",
      "  44      0.32930      0.32137        133.2\n",
      "  45      0.32744      0.32002        136.2\n",
      "  46      0.32561      0.31798        139.2\n",
      "  47      0.32391      0.31627        142.2\n",
      "  48      0.32216      0.31477        145.2\n",
      "  49      0.32051      0.31300        148.2\n",
      "  50      0.31881      0.31137        151.2\n",
      "  51      0.31714      0.31077        154.2\n",
      "  52      0.31548      0.30794        157.2\n",
      "  53      0.31391      0.30672        160.2\n",
      "  54      0.31246      0.30491        163.2\n",
      "  55      0.31063      0.30336        166.2\n",
      "  56      0.30912      0.30191        169.2\n",
      "  57      0.30752      0.30136        172.2\n",
      "  58      0.30600      0.29894        175.2\n",
      "  59      0.30470      0.29743        178.3\n",
      "  60      0.30295      0.29603        181.3\n",
      "  61      0.30152      0.29467        184.3\n",
      "  62      0.29992      0.29309        187.3\n",
      "  63      0.29859      0.29191        190.3\n",
      "  64      0.29722      0.29066        193.3\n",
      "  65      0.29586      0.28900        196.3\n",
      "  66      0.29446      0.28757        199.3\n",
      "  67      0.29285      0.28597        202.3\n",
      "  68      0.29152      0.28501        205.3\n",
      "  69      0.29028      0.28358        208.3\n",
      "  70      0.28899      0.28249        211.3\n",
      "  71      0.28768      0.28099        214.3\n",
      "  72      0.28638      0.27982        217.3\n",
      "  73      0.28487      0.27864        220.3\n",
      "  74      0.28372      0.27769        223.3\n",
      "  75      0.28250      0.27637        226.3\n",
      "  76      0.28134      0.27521        229.4\n",
      "  77      0.28013      0.27382        232.4\n",
      "  78      0.27895      0.27298        235.4\n",
      "  79      0.27778      0.27167        238.4\n",
      "  80      0.27647      0.27049        241.4\n",
      "  81      0.27522      0.26939        244.4\n",
      "  82      0.27432      0.26844        247.4\n",
      "  83      0.27329      0.26852\n",
      "Auto-stop. Use model at 82th iteration.\n",
      "\n",
      "Val logloss:  0.26844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26844"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libffm(libffm_path,train_libffm, val_libffm, 10, 6, lreg = 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['features'] = features\n",
    "sub.to_csv(base_path + 'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# looks promising -> 0.2684 for mob and  0.2386 for app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training part for the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# app model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ffm_txt_full(train, base_path, model_type, features_list, delta = 10**7, sample_size = 1.0):\n",
    "\n",
    "    if model_type == 'app':\n",
    "        train = train[train['site_id'] == '85f751fd']\n",
    "    else:\n",
    "        train = train[train['site_id'] != '85f751fd']\n",
    "        \n",
    "        \n",
    "    # process hour\n",
    "\n",
    "    train['day'] = train['hour'].map(get_day)\n",
    "    train['time'] = train['hour'].map(get_hour)\n",
    "    train['date'] = train['hour'].map(get_date)\n",
    "\n",
    "    # generate features\n",
    "\n",
    "    # define user as device_id + device_model + device_ip\n",
    "\n",
    "    train['user'] = train['device_id'] + train['device_model'] + train['device_ip']\n",
    "\n",
    "    # for each user we calculate his characteristics per hour, per day, total\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        dicty = train.groupby('temp')['user'].count()\n",
    "        train['user' + '_count_' + c] = train['temp'].map(dicty)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    for c in ['hour', 'date']:\n",
    "        train['temp'] = train['user'] + train[c].astype(str)\n",
    "        for cc in ['site_id', 'site_domain', 'site_category', 'app_id', 'app_domain',  'app_category', 'C14',\n",
    "           'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']:\n",
    "            dicty = train.groupby('temp')[cc].nunique()\n",
    "            train['user' + '_nunique_' + c + '_' + cc] = train['temp'].map(dicty)\n",
    "        print(c)\n",
    "    train.drop('temp', axis = 1, inplace = True)\n",
    "\n",
    "    # define an interaction of ad as site_id + app_id\n",
    "\n",
    "    train['place_id'] = train['site_id'] + train['app_id']\n",
    "    train['place_genre_id'] = train['site_id'] + train['app_id'] + train['site_category'] + train['app_category']\n",
    "    train['tech_position'] = train['banner_pos'].astype(str) + train['device_conn_type'].astype(str)\n",
    "    train['add_position'] = train['place_id'].astype(str) + train['banner_pos'].astype(str)\n",
    "    train['union_category'] = train['site_category'] + train['app_category']\n",
    "\n",
    "    train['ultra_C_type'] = train['C1'].astype(str) + train['C14'].astype(str) + train['C15'].astype(str) + train['C16'].astype(str) \\\n",
    "     + train['C17'].astype(str) + train['C18'].astype(str) + train['C19'].astype(str) + train['C20'].astype(str)+ train['C21'].astype(str)\n",
    "\n",
    "    \n",
    "\n",
    "    train['user_date'] = train['user'].astype(str) + train['date'].astype(str)\n",
    "    train['place_date'] = train['place_id'].astype(str) + train['date'].astype(str)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    history_user = []\n",
    "    history_place = []\n",
    "\n",
    "    dict_user = {}\n",
    "    dict_place = {}\n",
    "    \n",
    "    # for features user and place we calculate how oftern they are met per date in cummulative way\n",
    "\n",
    "    for row in train.itertuples():\n",
    "\n",
    "        user = row[list(train.columns).index('user_date') + 1]\n",
    "        place = row[list(train.columns).index('place_date') + 1]\n",
    "\n",
    "\n",
    "        try:\n",
    "            history_user.append(dict_user[user])\n",
    "        except KeyError:\n",
    "            history_user.append(0)\n",
    "        try:\n",
    "            history_place.append(dict_place[place])\n",
    "        except KeyError:\n",
    "            history_place.append(0)\n",
    "\n",
    "\n",
    "        try:\n",
    "            dict_user[user] += 1\n",
    "        except KeyError:\n",
    "            dict_user[user] = 0\n",
    "        try:\n",
    "            dict_place[place] += 1\n",
    "        except KeyError:\n",
    "            dict_place[place] = 0\n",
    "\n",
    "        if counter % 10**6 == 0:\n",
    "            print(counter / train.shape[0])\n",
    "        counter += 1\n",
    "\n",
    "    train['user_history'] = history_user\n",
    "    train.ix[train['user_history'] > 10*3, 'user_history'] = 1000\n",
    "    train['place_history'] = history_place\n",
    "    train.ix[train['place_history'] > 10*3, 'place_history'] = 1000\n",
    "    \n",
    "    train.drop(['user_date', 'place_date'], axis = 1, inplace = True)\n",
    "    \n",
    "    train = pd.concat([train[train['type'] == 1].sample(frac=sample_size, replace=False, random_state = 1),\n",
    "                       train[train['type'] == 0]])\n",
    "    \n",
    "    train.reset_index(inplace = True)\n",
    "    train.drop('index', inplace = True, axis = 1)\n",
    "        \n",
    "    train_shape = train[train['type'] == 1].shape[0]\n",
    "    train.drop('type', axis = 1, inplace = True)\n",
    "    \n",
    "    train_index = int(0.8*train_shape)\n",
    "    convert_to_ffm(train.ix[:train_index, :],'train',[],features_list,features_list, base_path, model_type = model_type)\n",
    "    convert_to_ffm(train.ix[train_index:train_shape - 1, :],'val',[],features_list,features_list, base_path, model_type = model_type)\n",
    "    convert_to_ffm(train.ix[train_shape:, :],'test',[],features_list,features_list, base_path, model_type = model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(base_path + 'train.gz')\n",
    "test = pd.read_csv(base_path + 'test.gz')\n",
    "test['click'] = 0\n",
    "\n",
    "train['type'] = 1\n",
    "test['type'] = 0\n",
    "\n",
    "cols = [t for t in train.columns]\n",
    "data = pd.concat([train[cols], test[cols]])\n",
    "\n",
    "\n",
    "features = list(pd.read_csv(base_path + 'features.csv')['features'].values)\n",
    "\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour\n",
      "date\n",
      "hour\n",
      "date\n",
      "0.0\n",
      "0.06129163165126827\n",
      "0.12258326330253654\n",
      "0.1838748949538048\n",
      "0.24516652660507307\n",
      "0.3064581582563413\n",
      "0.3677497899076096\n",
      "0.42904142155887787\n",
      "0.49033305321014614\n",
      "0.5516246848614144\n",
      "0.6129163165126826\n",
      "0.6742079481639509\n",
      "0.7354995798152192\n",
      "0.7967912114664875\n",
      "0.8580828431177557\n",
      "0.919374474769024\n",
      "0.9806661064202923\n",
      "Completed:  0.0\n",
      "Completed:  0.02\n",
      "Completed:  0.04\n",
      "Completed:  0.06\n",
      "Completed:  0.09\n",
      "Completed:  0.11\n",
      "Completed:  0.13\n",
      "Completed:  0.15\n",
      "Completed:  0.17\n",
      "Completed:  0.19\n",
      "Completed:  0.21\n",
      "Completed:  0.24\n",
      "Completed:  0.26\n",
      "Completed:  0.28\n",
      "Completed:  0.3\n",
      "Completed:  0.32\n",
      "Completed:  0.34\n",
      "Completed:  0.36\n",
      "Completed:  0.39\n",
      "Completed:  0.41\n",
      "Completed:  0.43\n",
      "Completed:  0.45\n",
      "Completed:  0.47\n",
      "Completed:  0.49\n",
      "Completed:  0.51\n",
      "Completed:  0.54\n",
      "Completed:  0.56\n",
      "Completed:  0.58\n",
      "Completed:  0.6\n",
      "Completed:  0.62\n",
      "Completed:  0.64\n",
      "Completed:  0.66\n",
      "Completed:  0.69\n",
      "Completed:  0.71\n",
      "Completed:  0.73\n",
      "Completed:  0.75\n",
      "Completed:  0.77\n",
      "Completed:  0.79\n",
      "Completed:  0.81\n"
     ]
    }
   ],
   "source": [
    "get_ffm_txt_full(data, base_path, 'app', features, sample_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mob model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(base_path + 'train.gz')\n",
    "test = pd.read_csv(base_path + 'test.gz')\n",
    "test['click'] = 0\n",
    "\n",
    "train['type'] = 1\n",
    "test['type'] = 0\n",
    "\n",
    "cols = [t for t in train.columns]\n",
    "data = pd.concat([train[cols], test[cols]])\n",
    "\n",
    "\n",
    "features = list(pd.read_csv(base_path + 'features.csv')['features'].values)\n",
    "\n",
    "del train\n",
    "del test\n",
    "\n",
    "get_ffm_txt_full(data, base_path, 'mob', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training and prediction for app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "libffm(libffm_path,train_libffm_a, val_libffm_a, 10, 6, autostop = True, lreg = 0.00002, print_s = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\avazu_feedzai\\libffm\\ffm-predict.exe D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt D:\\Downloads\\avazu_feedzai\\train_app_ffm.txt.model D:\\Downloads\\avazu_feedzai\\app_ffm.txt\n",
      "Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "libffm_predict(libffm_path_predict, model_a, train_libffm_a,  out_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training and prediction for mob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First check if the text file has already converted to binary format (0.0 seconds)\n",
      "Binary file NOT found. Convert text file to binary file (273.6 seconds)\n",
      "First check if the text file has already converted to binary format (0.0 seconds)\n",
      "Binary file NOT found. Convert text file to binary file (69.3 seconds)\n",
      "iter   tr_logloss   va_logloss      tr_time\n",
      "\n",
      "Val logloss:  -1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libffm(libffm_path,train_libffm_m, val_libffm_m, 10, 6, lreg = 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "libffm_predict(libffm_path_predict, model_m, test_libffm_m,  out_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# FTLR predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ftlr(ftlr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Combine libFFM predictions and then ensemble with FTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
